<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Noah Price">
<meta name="dcterms.date" content="2025-03-26">
<meta name="description" content="Noah Price Blog Post 4 - CSCI0451">

<title>Limits of the Quantitative Approach to Fairness – My Awesome CSCI 0451 Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-6de787833effe4777a6777a5e05fb578.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: white;
      }

      .quarto-title-block .quarto-title-banner {
        color: white;
background-image: url(../../img/landscape.png);
background-size: cover;
      }
</style>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">My Awesome CSCI 0451 Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About Noah P</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Limits of the Quantitative Approach to Fairness</h1>
                  <div>
        <div class="description">
          Noah Price Blog Post 4 - CSCI0451
        </div>
      </div>
                </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Noah Price </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 26, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>In his speech, Narayanan explains that while quantitative methods do have value and potential use cases, they have become overly trusted over time. Specifically, he mentions the common aphorism in statistics that “all models are wrong, but some models are useful” (<span class="citation" data-cites="narayanan2022">Narayanan (<a href="#ref-narayanan2022" role="doc-biblioref">2022</a>)</span>). Because statisticians are often forced to make the assumption that their model is ‘wrong’, or that its conclusions may be caused by factors which are irrelevant to the question at hand, they often end up simply defaulting to the <strong>null hypothesis</strong>, which is a term for the way we assume the world works without outside evidence. In the case of many models, this means disregarding quantitative evidence of bias, as the null hypothesis holds that there is no discrimination.</p>
<p>Narayanan also notes that the formal belief that the fields of statistics and computer science have held in objectivity may be faulty. In any given research paper, many subjective decisions are made which can alter the results (<span class="citation" data-cites="narayanan2022">Narayanan (<a href="#ref-narayanan2022" role="doc-biblioref">2022</a>)</span>). When we believe that a result is truly objective, it masks the reality that a human performed the given study. The impossibility of objectivity is further illustrated in our attempts to define fairness. Despite years of concerted effort, the aforementioned fields of research have failed to put forth a uniformly accepted definition of fairness (<span class="citation" data-cites="narayanan2022">Narayanan (<a href="#ref-narayanan2022" role="doc-biblioref">2022</a>)</span>). There may not exist an objective measure of fairness, and our constant pursuit of objectivity may prevent us from applying useful and important definitions of fairness.</p>
<p>All of this being said, Narayanan still does believe in quantitative work of some kind, noting in the end of his speech that there is still great value in describing datasets. Instead of creating models which draw conclusions <em>from</em> datasets, we may spend our effort understanding the nature of the datasets themselves. Historically, this work has been deemed merely descriptive, and lacking in original thought, which has devalued it, but Narayanan points out that we can learn a great deal from simple observation (<span class="citation" data-cites="narayanan2022">Narayanan (<a href="#ref-narayanan2022" role="doc-biblioref">2022</a>)</span>).</p>
<p>In some cases, quantitative methods of fairness can be effective tools for social progress. An example study where quantitative methods were used in a beneficial way was Sahin et. al’s study of a predictive model created for psychiatric treatment. The model in question used features such as race, gender, educational background, financial background, and more to predict whether patients at high risk of psychosis would enter psychosis imminently (<span class="citation" data-cites="sahin2024">Sahin et al. (<a href="#ref-sahin2024" role="doc-biblioref">2024</a>)</span>). It is easy to imagine the potential ethical problems posed by such a model if it exhibits bias. If its predictions were used to justify administering treatment, or, more drastically, people being sent to psychiatric wards, then inaccurate results could lead directly to harming patients.</p>
<p>Sahin et. al examined the model’s results for fairness via several quantitative measures, notably including equality of accuracy and predictive parity. Equality of accuracy requires that for all groups, the model makes correct predictions at the same rate (<span class="citation" data-cites="BHN2023">Barocas, Hardt, and Narayanan (<a href="#ref-BHN2023" role="doc-biblioref">2023</a>)</span>). Sahin et. al found that equality of accuracy was satisfied across all groups, with no statistically significant deviations. Predictive parity requires that that across all groups, the true positive rate, i.e.&nbsp;the rate at which patients were predicted to enter psychosis and did, is balanced (<span class="citation" data-cites="BHN2023">Barocas, Hardt, and Narayanan (<a href="#ref-BHN2023" role="doc-biblioref">2023</a>)</span>). While the model did show slightly higher positive predictive value for males overall, no trends reached statistical significance on this front. However, there was one statistically significant source of bias in the model, which was the false positive rate. Sahin et. al found that the false positive rate for patients with lower levels of education was higher than those with higher levels of education (<span class="citation" data-cites="sahin2024">Sahin et al. (<a href="#ref-sahin2024" role="doc-biblioref">2024</a>)</span>).</p>
<p>Despite the model satisfying some quantiative definitions of fairness, it showed bias in terms of level of education. This quantitative audit is reasonably useful in and of itself, as it provides some level of understanding of the model’s performance and preferences towards certain features. However, just understanding that the model favors certain features over others does not fully answer whether it is a fair model or not. More specifically, it would be useful to have some metric by which we can deem a model “fair enough” for use. As Narayanan points out, there is no objective truth, and true fairness in predictive models may be an impossibility given the layers of bias that are baked into aspects of machine learning. To account for this difficulty, Sahin et. al took their audit one step further.</p>
<p>By comparing the results of the model to the predictions of actual clinicians, Sahin et. al were able to evaluate their model relative to a benchmark, which provides a different perspective on fairness. While the model did show bias towards level of education, studies of clinician’s predictions revealed a similar bias (<span class="citation" data-cites="sahin2024">Sahin et al. (<a href="#ref-sahin2024" role="doc-biblioref">2024</a>)</span>). What this suggests is that while the model may be unfair by some quantitative definition, it is statistically no more unfair than the clinicians performing the work currently. Quantitative methods may not be able to perfectly capture the idea of fairness, but by comparing quantitative analysis of a model to quantitative analysis of human prediction, we may get closer to an acceptable definition of fairness. If we accept that potentially biased humans are ultimately responsible for other humans in some situations, then it is possible that potentially biased models could work as effectively.</p>
<p>However, even if we can find metrics by which a model could be “fair enough”, our methods for evaluating fairness may be subject to bias regardless. A model making ‘fair’ predictions within a biased system still lies within a biased system. Further, attempts to correct bias within a biased system may be counterproductive. In a case study on the “Stop, Question, Frisk” policy, Kallus &amp; Zhou examine how bias within datasets can perpetrate models in a way that cannot be corrected. Below is Figure 1 from Kallus &amp; Zhou’s paper, which illustrates how datasets can be subject to bias in their very collection (<span class="citation" data-cites="kallus2018">Kallus and Zhou (<a href="#ref-kallus2018" role="doc-biblioref">2018</a>)</span>).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./KallusFig1.png" class="img-fluid figure-img"></p>
<figcaption>Kallus &amp; Zhou Fig. 1</figcaption>
</figure>
</div>
<p>In this figure, the “biased decision policy” refers to the fact that when collecting data,humans are ultimately responsible for who is included and who is excluded. We only get to make predictions on the Z = 1 group, which are the included people in a dataset, but there often exists some excluded Z = 0 group. Because of the difficulty of collecting data on all people for whom a given model may be relevant, some (often many) constituents are bound to be left out of the datasets. In this case, even bias audits cannot capture the potential harms caused by incomplete data.</p>
<p>In their case study of SQF, for instance, Kallus &amp; Zhou examined how overpolicing of certain precincts in New York City leads to disproportionate data. In terms of D’Ignazio and Klein’s notion of the <em>Matrix of Domination</em>, the disciplinary domain is at work in this scenario, as overpolicing of certain precincts creates a biased data pool from which it is impossible to train fair models (<span class="citation" data-cites="d2023">D’ignazio and Klein (<a href="#ref-d2023" role="doc-biblioref">2023</a>)</span>). Figure 4 from Kallus &amp; Zhou, shown below, illustrates the problem clearly (<span class="citation" data-cites="kallus2018">Kallus and Zhou (<a href="#ref-kallus2018" role="doc-biblioref">2018</a>)</span>).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./KallusFig4.png" class="img-fluid figure-img"></p>
<figcaption>Kallus &amp; Zhou Fig. 4</figcaption>
</figure>
</div>
<p>If police target certain districts over other ones, any demographic differences between the highly policed districts and the underpoliced districts will be reflected in the training data. Statisticians are aware of this difficulty, and as a means of correcting it, will often use quantitative methods to correct the prediction rates as a means of enforcing fairness. To account for this, Kallus &amp; Zhou trained a logistic regression model to predict whether a given person is in criminal possession of a weapon, and then corrected the prediction rates according to two different principles: equality of opportunity and equality of odds. Under equality of opportunity, the true positive rate must be identical across all groups, and under equality of odds, both the true positive and false positive rates must be equal across all groups (<span class="citation" data-cites="BHN2023">Barocas, Hardt, and Narayanan (<a href="#ref-BHN2023" role="doc-biblioref">2023</a>)</span>). They then took the adjusted models and applied them to the full dataset of NYC’s population. The results are shown in Table 2 from their paper below (<span class="citation" data-cites="kallus2018">Kallus and Zhou (<a href="#ref-kallus2018" role="doc-biblioref">2018</a>)</span>).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./KallusTable2.png" class="img-fluid figure-img"></p>
<figcaption>Kallus &amp; Zhou Table 2</figcaption>
</figure>
</div>
<p>Even when equality of opportunity or equality of odds is satisfied, the model still shows systematic bias against certain groups when generalized to the true population of NYC. This is because the available training data is inherently biased, and current quantitative methods of enforcing fairness are insufficient for correcting this injustice.</p>
<p>The key problem at play in this case is that data is ultimately an abstraction of reality. When we create predictive models, we use features which describe certain attributes of a given person. These features mark an attempt to use quantitative reasoning to measure qualitative aspects of a human. Knowing someone’s highest level of education does not provide direct insight into how their brain operates, or even their level of intelligence; it is only an approximation of status. This approximation is known as a <em>measurement model</em>, and at the heart of this discussion of fairness is the issue of measurement (<span class="citation" data-cites="jw2021">Jacobs and Wallach (<a href="#ref-jw2021" role="doc-biblioref">2021</a>)</span>).</p>
<p>When we take a measurement of a given property, we are forced into making assumptions. For example, say we are predicting whether a prospective borrower will default on a bank loan. The pertinent data regarding a given borrower is essentially their socioeconomic status. The term “socioeconomic status”, unfortunately, refers to a wide sweep of factors, ranging from income to cost of living to occupation and more. When we use a feature such as income to approximate socioeconomic status, we abstract away all other relevant factors, which leaves us with an imperfect picture. Jacobs &amp; Wallach contend that these assumptions remain essentially undiscussed in computer science, and pose a significant theoretical problem to fairness in machine learning (<span class="citation" data-cites="jw2021">Jacobs and Wallach (<a href="#ref-jw2021" role="doc-biblioref">2021</a>)</span>).</p>
<p>Quantitative definitions of fairness are subject to similar issues of assumption. Attempting to measure fairness as a mathematical property is an abstraction of our real understanding of fairness in moral terms. Humans have varying understandings of the term “equality of opportunity”, for example, which means that measuring equality of opportunity statistically is not going to be accurate for everyone (<span class="citation" data-cites="BHN2023">Barocas, Hardt, and Narayanan (<a href="#ref-BHN2023" role="doc-biblioref">2023</a>)</span>). When we deem a certain mathematical explanation “fair”, we risk adoption of that definition without a critical examination of how it falls into our intuitive understandings of fairness (<span class="citation" data-cites="jw2021">Jacobs and Wallach (<a href="#ref-jw2021" role="doc-biblioref">2021</a>)</span>).</p>
<p>To return to Narayanan’s position with all of this in mind, the claim that quantative methods do more harm than good is worthy of careful consideration. As shown by the case studies of Sahin et. al and Kallus &amp; Zhou, quantitative methods may provide some insight as to how models operate across various groups, but answering for whether they are “fair” or not requires further study and intervention. The predominant acceptance of quantitative methods has allowed many unfair models to be justified, when the actual academic philosophical debate on the issue of fairness remains in a state of aporia. Until we can formalize methods for using and creating models which we deem fair within an acceptable standard, quantitative methods of evaluation largely allow for misrepresentations of equality.</p>




<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-BHN2023" class="csl-entry" role="listitem">
Barocas, Solon, Moritz Hardt, and Arvind Narayanan. 2023. <em>Fairness and Machine Learning: Limitations and Opportunities</em>. <span>Cambridge, Massachusetts</span>: <span>The MIT Press</span>.
</div>
<div id="ref-d2023" class="csl-entry" role="listitem">
D’ignazio, Catherine, and Lauren F Klein. 2023. <em>Data Feminism</em>. MIT press.
</div>
<div id="ref-jw2021" class="csl-entry" role="listitem">
Jacobs, Abigail Z., and Hanna Wallach. 2021. <span>“Measurement and Fairness.”</span> In <em>Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em>, 375–85. FAccT ’21. New York, NY, USA: Association for Computing Machinery. <a href="https://doi.org/10.1145/3442188.3445901">https://doi.org/10.1145/3442188.3445901</a>.
</div>
<div id="ref-kallus2018" class="csl-entry" role="listitem">
Kallus, Nathan, and Angela Zhou. 2018. <span>“Residual Unfairness in Fair Machine Learning from Prejudiced Data.”</span> <a href="https://arxiv.org/abs/1806.02887">https://arxiv.org/abs/1806.02887</a>.
</div>
<div id="ref-narayanan2022" class="csl-entry" role="listitem">
Narayanan, Arvind. 2022. <span>“The Limits of the Quantitative Approach to Discrimination.”</span> Speech.
</div>
<div id="ref-sahin2024" class="csl-entry" role="listitem">
Sahin, Derya et al. 2024. <span>“Algorithmic Fairness in Precision Psychiatry: Analysis of Prediction Models in Individuals at Clinical High Risk for Psychosis.”</span> <em>The British Journal of Psychiatry</em> 224 (2): 55–65. <a href="https://doi.org/10.1192/bjp.2023.141">https://doi.org/10.1192/bjp.2023.141</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>